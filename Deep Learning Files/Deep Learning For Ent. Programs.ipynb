{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2728a71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                352       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 385\n",
      "Trainable params: 385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Program 1:\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Build a simple neural network with ReLU activation\n",
    "model = models.Sequential([\n",
    "    layers.Dense(32, input_shape=(10,), activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b20ab74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data: [0.5 0.3 0.2]\n",
      "Weights: [0.46353624 0.80029125 0.23403905]\n",
      "Bias: [0.06518426]\n",
      "Weighted Sum: [0.58384757]\n",
      "Output after Sigmoid Activation: [0.64195225]\n"
     ]
    }
   ],
   "source": [
    "# Program 2:\n",
    "import numpy as np\n",
    "class Neuron:\n",
    "    def __init__(self, input_size):\n",
    "        # Initialize weights and bias randomly\n",
    "        self.weights = np.random.rand(input_size)\n",
    "        self.bias = np.random.rand(1)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        # Sigmoid activation function\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Perform a forward pass through the neuron\n",
    "        weighted_sum = np.dot(inputs, self.weights) + self.bias\n",
    "        output = self.sigmoid(weighted_sum)\n",
    "        return output\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a neuron with 3 input features\n",
    "    neuron = Neuron(input_size=3)\n",
    "\n",
    "    # Input data for a single example\n",
    "    input_data = np.array([0.5, 0.3, 0.2])\n",
    "\n",
    "    # Perform a forward pass through the neuron\n",
    "    output = neuron.forward(input_data)\n",
    "\n",
    "    # Display the results\n",
    "    print(\"Input Data:\", input_data)\n",
    "    print(\"Weights:\", neuron.weights)\n",
    "    print(\"Bias:\", neuron.bias)\n",
    "    print(\"Weighted Sum:\", np.dot(input_data, neuron.weights) + neuron.bias)\n",
    "    print(\"Output after Sigmoid Activation:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceae2050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Dense)          (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Program 3:\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# Create a simple dataset for demonstration\n",
    "X = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "y = [0, 1, 1, 0]\n",
    "\n",
    "# Define a fully connected neural network with SGD optimizer\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer with 2 neurons\n",
    "model.add(Dense(units=2, input_dim=2, activation='relu', name='input_layer'))\n",
    "\n",
    "# Output layer with 1 neuron (binary classification)\n",
    "model.add(Dense(units=1, activation='sigmoid', name='output_layer'))\n",
    "\n",
    "# Compile the model with Stochastic Gradient Descent (SGD) optimizer\n",
    "sgd_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "model.compile(optimizer=sgd_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c5253f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 128)               12928     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 784)               101136    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 114,064\n",
      "Trainable params: 114,064\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Program 4:\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the generator model\n",
    "def build_generator(latent_dim):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(128, input_dim=latent_dim, activation='relu'))\n",
    "    model.add(layers.Dense(784, activation='sigmoid'))\n",
    "    model.add(layers.Reshape((28, 28, 1)))\n",
    "    return model\n",
    "\n",
    "# Build the generator\n",
    "latent_dim = 100\n",
    "generator = build_generator(latent_dim)\n",
    "\n",
    "# Display the generator summary\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66cb7e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 100,609\n",
      "Trainable params: 100,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Program 5:\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the discriminator model\n",
    "def build_discriminator(input_shape=(28, 28, 1)):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=input_shape))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Build the discriminator\n",
    "discriminator = build_discriminator()\n",
    "\n",
    "# Display the discriminator summary\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b74da45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Dense)          (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.5255 - accuracy: 0.7500\n",
      "\n",
      "Evaluation - Loss: 0.5255492329597473, Accuracy: 0.75\n",
      "\n",
      "Hidden Layer Activation:\n",
      "[[0.        1.1805922]]\n",
      "\n",
      "Output Layer Activation:\n",
      "[[0.84069824]]\n"
     ]
    }
   ],
   "source": [
    "# Program 6: \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# Create a simple dataset for demonstration\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# Define a simple neural network with one hidden layer and a specific activation function\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer (2 input nodes)\n",
    "model.add(Dense(units=2, input_dim=2, activation='relu', name='input_layer'))\n",
    "\n",
    "# Hidden layer with a specific activation function (e.g., sigmoid)\n",
    "model.add(Dense(units=1, activation='sigmoid', name='output_layer'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model on the dataset\n",
    "model.fit(X, y, epochs=1000, verbose=0)\n",
    "\n",
    "# Evaluate the trained model\n",
    "loss, accuracy = model.evaluate(X, y)\n",
    "print(f'\\nEvaluation - Loss: {loss}, Accuracy: {accuracy}')\n",
    "\n",
    "# Display the activations of the hidden layer for a sample input\n",
    "sample_input = np.array([[0, 1]])\n",
    "hidden_layer_activation = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer('input_layer').output).predict(sample_input)\n",
    "output_activation = Model(inputs=model.input, \n",
    "                          outputs=model.get_layer('output_layer').output).predict(sample_input)\n",
    "print(\"\\nHidden Layer Activation:\")\n",
    "print(hidden_layer_activation)\n",
    "\n",
    "print(\"\\nOutput Layer Activation:\")\n",
    "print(output_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67be61e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                25120     \n",
      "=================================================================\n",
      "Total params: 25,120\n",
      "Trainable params: 25,120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Program 7:\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to the range [0, 1]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Flatten the images\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "# Build the autoencoder model with an encoder and decoder\n",
    "encoding_dim = 32  # Number of neurons in the bottleneck layer\n",
    "\n",
    "# Input layer\n",
    "input_img = tf.keras.Input(shape=(784,))\n",
    "\n",
    "# Encoder\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
    "\n",
    "# Decoder (not used in this example, but included for completeness)\n",
    "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# Autoencoder model\n",
    "autoencoder = models.Model(input_img, decoded)\n",
    "\n",
    "# Encoder model (only includes the encoder part)\n",
    "encoder = models.Model(input_img, encoded)\n",
    "\n",
    "# Compile the autoencoder (not used in this example, but included for completeness)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Display the encoder model summary\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5babb940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 784)               25872     \n",
      "=================================================================\n",
      "Total params: 25,872\n",
      "Trainable params: 25,872\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Program 8:\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to the range [0, 1]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Flatten the images\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "# Build the autoencoder model with an encoder and decoder\n",
    "encoding_dim = 32  # Number of neurons in the bottleneck layer\n",
    "\n",
    "# Input layer\n",
    "input_img = tf.keras.Input(shape=(784,))\n",
    "\n",
    "# Encoder\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
    "\n",
    "# Decoder\n",
    "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# Autoencoder model\n",
    "autoencoder = models.Model(input_img, decoded)\n",
    "\n",
    "# Decoder model (only includes the decoder part)\n",
    "decoder_input = tf.keras.Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]  # Use the last layer of the autoencoder\n",
    "decoder = models.Model(decoder_input, decoder_layer(decoder_input))\n",
    "\n",
    "# Compile the autoencoder (not used in this example, but included for completeness)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Display the decoder model summary\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3877b1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 55\n",
      "Trainable params: 55\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Original Data:\n",
      "[0.84292158 0.52975721 0.79121258 0.28516277 0.08029    0.43078745\n",
      " 0.43391456 0.47488537 0.5187685  0.48892646]\n",
      "Encoded Data:\n",
      "[0.5135934 0.598009  0.        0.9055654 0.       ]\n"
     ]
    }
   ],
   "source": [
    "# Program 9:\n",
    "# Import necessary libraries\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "# Create a simple dataset for demonstration\n",
    "# Each data point is a vector of length 10\n",
    "# You can replace this with your own dataset\n",
    "data = np.random.random((1000, 10))\n",
    "\n",
    "# Define the architecture of the encoder\n",
    "input_data = Input(shape=(10,))\n",
    "encoded = Dense(5, activation='relu')(input_data)  # Encoder layer with 5 neurons\n",
    "\n",
    "# Create the encoder model\n",
    "encoder_model = Model(input_data, encoded)\n",
    "\n",
    "# Compile the encoder model (not necessary for an encoder, but included for completeness)\n",
    "encoder_model.compile(optimizer='adam', loss='mse')  # Use mean squared error as a dummy loss\n",
    "\n",
    "# Display the architecture of the encoder\n",
    "encoder_model.summary()\n",
    "\n",
    "# Encode the data using the trained encoder\n",
    "encoded_data = encoder_model.predict(data)\n",
    "\n",
    "# Display the original and encoded data for the first example\n",
    "print(\"Original Data:\")\n",
    "print(data[0])\n",
    "print(\"Encoded Data:\")\n",
    "print(encoded_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "040c7d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data:\n",
      "[[-1.01283112]\n",
      " [ 0.31424733]\n",
      " [-0.90802408]]\n",
      "\n",
      "Output of the Neural Network:\n",
      "[[0.25942616]]\n"
     ]
    }
   ],
   "source": [
    "# Program 10:\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Define a simple neural network with random weights and biases\n",
    "def initialize_parameters(input_size, hidden_size, output_size):\n",
    "    np.random.seed(42)\n",
    "    W1 = np.random.randn(hidden_size, input_size)  # Weights for the first layer\n",
    "    b1 = np.zeros((hidden_size, 1))  # Biases for the first layer\n",
    "    W2 = np.random.randn(output_size, hidden_size)  # Weights for the second layer\n",
    "    b2 = np.zeros((output_size, 1))  # Biases for the second layer\n",
    "\n",
    "    parameters = {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n",
    "    return parameters\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    # Retrieve parameters\n",
    "    W1, b1, W2, b2 = parameters[\"W1\"], parameters[\"b1\"], parameters[\"W2\"], parameters[\"b2\"]\n",
    "\n",
    "    # Forward pass through the first layer\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "\n",
    "    # Forward pass through the second layer\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "\n",
    "    # Output of the neural network\n",
    "    output = A2\n",
    "    return output\n",
    "\n",
    "# Example usage\n",
    "input_size = 3\n",
    "hidden_size = 4\n",
    "output_size = 1\n",
    "\n",
    "# Initialize random parameters\n",
    "parameters = initialize_parameters(input_size, hidden_size, output_size)\n",
    "\n",
    "# Generate random input data\n",
    "X = np.random.randn(input_size, 1)\n",
    "\n",
    "# Perform forward propagation\n",
    "output = forward_propagation(X, parameters)\n",
    "\n",
    "# Display the input data and the output of the neural network\n",
    "print(\"Input Data:\")\n",
    "print(X)\n",
    "print(\"\\nOutput of the Neural Network:\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76ba7c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data: [0.5 0.3 0.2]\n",
      "Weights: [-1.4123037   1.46564877 -0.2257763 ]\n",
      "Bias: 0.06752820468792384\n",
      "Output: -0.2440842754005629\n"
     ]
    }
   ],
   "source": [
    "# Program 11:\n",
    "import numpy as np\n",
    "def linear_activation(inputs, weights, bias):\n",
    "    \"\"\"\n",
    "    Perform a linear activation (weighted sum + bias) for a neural network layer.\n",
    "    Args:\n",
    "    - inputs: Input data (numpy array)\n",
    "    - weights: Weights for the layer (numpy array)\n",
    "    - bias: Bias for the layer (scalar)\n",
    "    Returns:\n",
    "    - output: Output of the layer (numpy array)\n",
    "    \"\"\"\n",
    "    weighted_sum = np.dot(inputs, weights) + bias\n",
    "    return weighted_sum\n",
    "\n",
    "# Define a simple neural network layer with bias\n",
    "input_size = 3\n",
    "output_size = 1\n",
    "\n",
    "# Randomly initialize weights and bias\n",
    "weights = np.random.randn(input_size)\n",
    "bias = np.random.randn()\n",
    "\n",
    "# Create input data\n",
    "input_data = np.array([0.5, 0.3, 0.2])\n",
    "\n",
    "# Perform a forward pass through the layer\n",
    "output = linear_activation(input_data, weights, bias)\n",
    "\n",
    "# Display the input data, weights, bias, and output\n",
    "print(\"Input Data:\", input_data)\n",
    "print(\"Weights:\", weights)\n",
    "print(\"Bias:\", bias)\n",
    "print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e644832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal x value: 0.04611686018427388\n",
      "Optimal y value (minimized): 0.0021267647932558657\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Program 12:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to compute the gradient of a quadratic function\n",
    "def compute_gradient(x):\n",
    "    return 2 * x\n",
    "\n",
    "# Gradient Descent function\n",
    "def gradient_descent(initial_x, learning_rate, num_iterations):\n",
    "    \"\"\"\n",
    "    Perform gradient descent optimization on a quadratic function.\n",
    "    Args:\n",
    "    - initial_x: Initial guess for the minimum (scalar)\n",
    "    - learning_rate: Step size for each iteration (scalar)\n",
    "    - num_iterations: Number of iterations to perform (integer)\n",
    "    Returns:\n",
    "    - x_values: List of x values during the optimization (list)\n",
    "    - y_values: List of y values (quadratic function) during the optimization (list)\n",
    "    \"\"\"\n",
    "    x_values = []\n",
    "    y_values = []\n",
    "\n",
    "    x = initial_x\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        # Compute the gradient\n",
    "        gradient = compute_gradient(x)\n",
    "\n",
    "        # Update the value of x using gradient descent\n",
    "        x = x - learning_rate * gradient\n",
    "\n",
    "        # Calculate the corresponding y value (quadratic function)\n",
    "        y = x**2\n",
    "\n",
    "        # Store the values for visualization\n",
    "        x_values.append(x)\n",
    "        y_values.append(y)\n",
    "\n",
    "    return x_values, y_values\n",
    "\n",
    "# Initial parameters\n",
    "initial_guess = 4.0\n",
    "learning_rate = 0.1\n",
    "num_iterations = 20\n",
    "\n",
    "# Perform gradient descent\n",
    "x_values, y_values = gradient_descent(initial_guess, learning_rate, num_iterations)\n",
    "\n",
    "# Display the results\n",
    "print(\"Optimal x value:\", x_values[-1])\n",
    "print(\"Optimal y value (minimized):\", y_values[-1])\n",
    "\n",
    "# Plot the optimization process\n",
    "plt.plot(range(num_iterations), y_values, marker='o')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Quadratic Function Value')\n",
    "plt.title('Gradient Descent Optimization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2090de0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Dense)          (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.5028 - accuracy: 0.7500\n",
      "\n",
      "Evaluation - Loss: 0.5028179883956909, Accuracy: 0.75\n",
      "\n",
      "Learned Weights:\n",
      "output_layer Weights: \n",
      "[[ 1.913241 ]\n",
      " [-0.6327765]]\n"
     ]
    }
   ],
   "source": [
    "# Program 13:\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# Create a simple dataset for demonstration\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# Define a simple neural network with one hidden layer\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer (2 input nodes)\n",
    "model.add(Dense(units=2, input_dim=2, activation='relu', name='input_layer'))\n",
    "\n",
    "# Hidden layer with weights to be defined\n",
    "model.add(Dense(units=1, activation='sigmoid', name='output_layer'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model on the dataset\n",
    "model.fit(X, y, epochs=1000, verbose=0)\n",
    "\n",
    "# Evaluate the trained model\n",
    "loss, accuracy = model.evaluate(X, y)\n",
    "print(f'\\nEvaluation - Loss: {loss}, Accuracy: {accuracy}')\n",
    "\n",
    "# Display the learned weights\n",
    "print(\"\\nLearned Weights:\")\n",
    "for layer in model.layers:\n",
    "    if 'Dense' in layer.name:\n",
    "        weights, biases = layer.get_weights()\n",
    "print(f\"{layer.name} Weights: \\n{weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f42f889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Dense)          (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.5683 - accuracy: 0.7500\n",
      "\n",
      "Evaluation - Loss: 0.5682690739631653, Accuracy: 0.75\n",
      "\n",
      "Learned Biases:\n",
      "output_layer Biases:[-0.41911563]\n"
     ]
    }
   ],
   "source": [
    "# Program 14:\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# Create a simple dataset for demonstration\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# Define a simple neural network with one hidden layer\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer (2 input nodes)\n",
    "model.add(Dense(units=2, input_dim=2, activation='relu', use_bias=True, name='input_layer'))\n",
    "\n",
    "# Hidden layer with biases to be defined\n",
    "model.add(Dense(units=1, activation='sigmoid', use_bias=True, name='output_layer'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model on the dataset\n",
    "model.fit(X, y, epochs=1000, verbose=0)\n",
    "\n",
    "# Evaluate the trained model\n",
    "loss, accuracy = model.evaluate(X, y)\n",
    "print(f'\\nEvaluation - Loss: {loss}, Accuracy: {accuracy}')\n",
    "\n",
    "# Display the learned biases\n",
    "print(\"\\nLearned Biases:\")\n",
    "for layer in model.layers:\n",
    "    if 'Dense' in layer.name:\n",
    "        weights, biases = layer.get_weights()\n",
    "print(f\"{layer.name} Biases:{biases}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "466d65fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                352       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 385\n",
      "Trainable params: 385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 3s 38ms/step - loss: 0.7165 - accuracy: 0.5125 - val_loss: 0.7165 - val_accuracy: 0.5050\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.7058 - accuracy: 0.5138 - val_loss: 0.7099 - val_accuracy: 0.5050\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.6992 - accuracy: 0.5188 - val_loss: 0.7063 - val_accuracy: 0.5150\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.6945 - accuracy: 0.5275 - val_loss: 0.7039 - val_accuracy: 0.5100\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.6907 - accuracy: 0.5312 - val_loss: 0.7027 - val_accuracy: 0.5250\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.6880 - accuracy: 0.5362 - val_loss: 0.7018 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.6853 - accuracy: 0.5425 - val_loss: 0.7020 - val_accuracy: 0.4800\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 20ms/step - loss: 0.6831 - accuracy: 0.5575 - val_loss: 0.7018 - val_accuracy: 0.4700\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.6812 - accuracy: 0.5638 - val_loss: 0.7014 - val_accuracy: 0.4750\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 1s 27ms/step - loss: 0.6799 - accuracy: 0.5612 - val_loss: 0.7017 - val_accuracy: 0.4800\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7017 - accuracy: 0.4800\n",
      "Test accuracy: 0.47999998927116394\n"
     ]
    }
   ],
   "source": [
    "# Program 15:\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import models, layers\n",
    "\t\n",
    "# Generate synthetic data for a binary classification task\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(1000, 10)  # 1000 samples with 10 features\n",
    "y = np.random.randint(2, size=(1000, 1))  # Binary labels (0 or 1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build the ANN model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051028aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
